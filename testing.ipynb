{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random, sample\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    Trainer, TrainingArguments\n",
    ")\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_file, block_size=256):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.pad = self.tokenizer.encode(self.tokenizer.eos_token)[0]\n",
    "        self.data = {\n",
    "            'train': [],\n",
    "            'validation': []\n",
    "        }\n",
    "        self.data['train'] = self.generate_dateset(text_file)\n",
    "        self.data['validation'] = self.generate_dateset(\n",
    "            text_file, eval=True, split=0.1)\n",
    "\n",
    "    def generate_dateset(self, text_file, eval=False, split=0.1):\n",
    "        data = []\n",
    "        with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read().split(\"<BREAK>\")\n",
    "            if eval:\n",
    "                text = sample(text, int(len(text)*split))\n",
    "\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "        for t in text:\n",
    "            input_ids.extend(self.tokenizer.encode(t))\n",
    "            attention_mask.extend([1 for i in range(len(input_ids))])\n",
    "        input_ids = self.pad_list(input_ids)\n",
    "        attention_mask = self.pad_list(attention_mask)\n",
    "        id_chunks = list(self.chunks(input_ids, self.block_size))\n",
    "        attm_chunks = list(self.chunks(attention_mask, self.block_size))\n",
    "\n",
    "        for id, mask in zip(id_chunks, attm_chunks):\n",
    "            data.append({\n",
    "                'input_ids': torch.tensor(id),\n",
    "                'attention_mask': torch.tensor(mask),\n",
    "                'labels': torch.tensor(id.copy())\n",
    "            })\n",
    "        return data\n",
    "    \n",
    "    def pad_list(self, input_ids):\n",
    "        padding = self.block_size - (len(input_ids) % self.block_size)\n",
    "        _ = [input_ids.append(self.pad) for _ in range(padding)]\n",
    "        return input_ids\n",
    "\n",
    "    def chunks(self, lst, n):\n",
    "        \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "\n",
    "def group_texts(examples, block_size=1024):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i: i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer and Model objects\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "block_size = 512\n",
    "dataset = TextDataset(\"corpus.txt\", block_size=block_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset[\"train\"],\n",
    "    batch_size=block_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset[\"validation\"],\n",
    "    batch_size=block_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"ethical\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-gpt2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=15,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    optimizers=(optimizer, None),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f3900779cf4cbcbf11ddd7decf0612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96be925ff1d24284ab9124fe8041a02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab01ec58174f440881b640e698f9012f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.286198616027832, 'eval_runtime': 0.8302, 'eval_samples_per_second': 38.545, 'eval_steps_per_second': 38.545, 'epoch': 10.0}\n",
      "{'loss': 3.3067, 'learning_rate': 5.370950888192268e-06, 'epoch': 10.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e03194170347a9bc2898196d0914d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2520198822021484, 'eval_runtime': 0.8348, 'eval_samples_per_second': 38.331, 'eval_steps_per_second': 38.331, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf4b932f9d649c6be28601cde8350f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.229323625564575, 'eval_runtime': 0.8531, 'eval_samples_per_second': 37.509, 'eval_steps_per_second': 37.509, 'epoch': 12.0}\n",
      "{'loss': 3.2592, 'learning_rate': 3.2810867293625914e-06, 'epoch': 12.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1a252f396c45d7af3d11de46c3879c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.211854934692383, 'eval_runtime': 0.8528, 'eval_samples_per_second': 37.524, 'eval_steps_per_second': 37.524, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a90160e123f4b3ead836b4c6c12ab8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2013602256774902, 'eval_runtime': 0.8474, 'eval_samples_per_second': 37.762, 'eval_steps_per_second': 37.762, 'epoch': 14.0}\n",
      "{'loss': 3.2138, 'learning_rate': 1.1912225705329155e-06, 'epoch': 14.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a5afc3f8584be492c2a95a27dce07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1971094608306885, 'eval_runtime': 0.8284, 'eval_samples_per_second': 38.63, 'eval_steps_per_second': 38.63, 'epoch': 15.0}\n",
      "{'train_runtime': 216.0371, 'train_samples_per_second': 22.149, 'train_steps_per_second': 22.149, 'train_loss': 1.213298049017927, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4785, training_loss=1.213298049017927, metrics={'train_runtime': 216.0371, 'train_samples_per_second': 22.149, 'train_steps_per_second': 22.149, 'train_loss': 1.213298049017927, 'epoch': 15.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(\n",
    "    resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"ethical-finetuned-gpt2\\checkpoint-4500\")\n",
    "input = tokenizer.encode(\"Artificial Intelligence has societal\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8001,  9542,  9345,   468, 26877]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Travis Weston\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'every lived experience of the world: what that experience represents.\" This is not a problem for Bajorans with marginalized backgrounds, but those who are able and willing to work toward making a difference: the whole concept of marginalization isn\\'t only unproductive'},\n",
       " {'generated_text': 'every lived experience of the world may, or may not, differ from the real world. Factors include social, economic and institutional factors. The social, biological, psychological, philosophical, philosophical, scientific, and technological systems of measurement have been able to make'},\n",
       " {'generated_text': 'every lived experience of the world, then there must be some kind of thing that can be said as meaningful to these questions. We have to be able to talk literally about all the lived experiences of the world, and we have to have a sense of'},\n",
       " {'generated_text': 'every lived experience of the world, one way i can easily tell you is that, frankly, the people who make up the majority of these systems and how they process and use information, are probably right- wing and prejudiced. As long as they'},\n",
       " {'generated_text': 'every lived experience of the world. I don\\'t know how to do that. Just a basic example of how to survive a climate change pandemic. \"These people are not worthy of respect, compassion, or love. They are toxic. They are'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"every lived experience of the world\", max_length=50, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Travis Weston\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'every lived experience of the world: what that experience represents.\" This is not a problem for any single “person\", as John Locke would have it, for every “human mind\" to be exactly the same, or at least to be the'},\n",
       " {'generated_text': 'every lived experience of the world may, or may not, differ from the real world. But we should not forget that there are some places in the world in which we live in which we know very little about the world, some situations in which we'},\n",
       " {'generated_text': 'every lived experience of the world, then there must be some kind of thing that can be said as meaningful to these questions. We have to be able to talk literally about these things; to know that they exist, and to believe them to exist in'},\n",
       " {'generated_text': 'every lived experience of the world, one way i can easily tell you is that, frankly, the people who make up the majority of these systems and how they process and use information, are probably right-wing and prejudiced. As long as they'},\n",
       " {'generated_text': \"every lived experience of the world. I don't know why it doesn't have an equal shot at the recognition of both knowledge and value. I don't know that it'll have a singular, singular, singular, singularly necessary place to exist.\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"every lived experience of the world\", max_length=50, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The impact of technology on society, on humanity and the future of humanity is always shifting. Each of these shifts will have unintended long-term consequences, each of the technologies involved will change both the way people see this world and the way society and technology'},\n",
       " {'generated_text': 'The impact of technology on society and on the world will continue to play out throughout the years. But while technology creates opportunities for change and greater freedom, it also erodes the foundations upon which society has stood. So here are five steps toward making a'},\n",
       " {'generated_text': 'The impact of technology on society will be very small. The impacts of innovation will increase as the amount of human knowledge is vastly reduced and our brains radically improved, and we are being built into new interfaces and interfaces with technologies that already degrade and destroy us'},\n",
       " {'generated_text': 'The impact of technology on society has continued, with anthropomorphic augmented reality technologies such as augmented reality glasses and facial recognition, and other digital technologies that allow people to change faces. Today, digital cameras, artificial intelligence, robotics, and even 3D printed'},\n",
       " {'generated_text': \"The impact of technology on society is far greater than just how this plays out on the streets, and it's going to continue to be a real fight. We must fight back to make this happen, both within and outside of technology. Because if we\"}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"\", max_length=50, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do Large Language models work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define two sentences to compare the embeddings of\n",
    "sentence1 = \"People are subject to the same moral obligations in virtual worlds as they are in the physical world.\"\n",
    "sentence2 = \"It is a moral obligation to ensure that the use of artificial intelligence does not infringe rights.\"\n",
    "sentence3 = \"People are subject to the same moral obligations in virtual worlds as they are in the physical world.\"\n",
    "sentence4 = \"It is a moral obligation to ensure that the use of artificial intelligence does not infringe rights.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained tokenizer from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer and Model objects\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8061,   389,  2426,   284,   262,   976,  6573, 13675,   287,\n",
       "         7166, 11621,   355,   484,   389,   287,   262,  3518,   995,\n",
       "           13]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1 = tokenizer.encode(sentence1, return_tensors=\"np\")\n",
    "embeddings2 = tokenizer.encode(sentence2, return_tensors=\"np\")\n",
    "embeddings3 = tokenizer.encode(sentence3, return_tensors=\"np\")\n",
    "embeddings4 = tokenizer.encode(sentence4, return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1026,   318,   257,  6573, 12990,   284,  4155,   326,   262,\n",
       "          779,   286, 11666,  4430,   857,   407, 14020,    68,  2489,\n",
       "           13]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2 = tokenizer.encode(sentence2, return_tensors=\"np\")\n",
    "embeddings2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each number in the list of embeddings represents a word in a dictionary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People\n",
      "are\n",
      "subject\n",
      "to\n",
      "the\n",
      "same\n",
      "moral\n",
      "obligations\n",
      "in\n",
      "virtual\n",
      "worlds\n",
      "as\n",
      "they\n",
      "are\n",
      "in\n",
      "the\n",
      "physical\n",
      "world\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# loop through the embeddings and print the decoded text\n",
    "tokens1 = []\n",
    "for i in range(len(embeddings1[0])):\n",
    "    print(tokenizer.decode(embeddings1[0][i]).strip())\n",
    "    tokens1.append(tokenizer.decode(embeddings1[0][i]).strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8061])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate cosine similarity between the two embeddings\n",
    "similarity = cosine_similarity(embeddings1.reshape(1,-1), embeddings2.reshape(1,-1))\n",
    "\n",
    "# Plot the embeddings\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(embeddings1[:,0], embeddings1[:,1], color='blue', label='Sentence 1')\n",
    "ax.scatter(embeddings2[:,0], embeddings2[:,1], color='green', label='Sentence 2')\n",
    "ax.set_title(f'Similarity: {round(similarity[0][0], 2)}')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8061,   389,  2426,   284,   262,   976,  6573, 13675,   287,\n",
       "         7166, 11621,   355,   484,   389,   287,   262,  3518,   995,\n",
       "           13]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1[0].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = np.stack((embeddings1[0], embeddings2[0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8061"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Reduce the dimensionality of the embeddings to 3 using PCA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pca \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m reduced_embeddings \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(embs[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\Travis Weston\\.conda\\envs\\torchgpu\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1118\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \n\u001b[0;32m   1099\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[39m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m-> 1118\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[0;32m   1119\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[0;32m   1120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[1;32mc:\\Users\\Travis Weston\\.conda\\envs\\torchgpu\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:829\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 829\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "# Reduce the dimensionality of the embeddings to 3 using PCA\n",
    "pca = TSNE(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(embs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Reduce the dimensionality of the embeddings to 3 using PCA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m reduced_embeddings \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(embs)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Plot the embeddings in 3D\u001b[39;00m\n\u001b[0;32m      6\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n",
      "File \u001b[1;32mc:\\Users\\Travis Weston\\.conda\\envs\\torchgpu\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Travis Weston\\.conda\\envs\\torchgpu\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Travis Weston\\.conda\\envs\\torchgpu\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_full(X, n_components)\n\u001b[0;32m    513\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    514\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_truncated(X, n_components, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32mc:\\Users\\Travis Weston\\.conda\\envs\\torchgpu\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    523\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmle\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is only supported if n_samples >= n_features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         )\n\u001b[0;32m    525\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n_components \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m must be between 0 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmin(n_samples, n_features)=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msvd_solver=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_components, \u001b[39mmin\u001b[39m(n_samples, n_features))\n\u001b[0;32m    530\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[39m# Center data\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plot the embeddings in 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i, word in enumerate(tokens1):\n",
    "    x, y, z = reduced_embeddings[i,:]\n",
    "    ax.scatter(x, y, z, color='blue')\n",
    "    ax.text(x, y, z, word, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().split(\"<BREAK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(text) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(text, int(len(text) * 0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
